- [Preview](#preview)
- [Design](#design)
- [Functional Requirements](#functional_requirements)
- [Non Function](#non_function)
- [Explain Common](#explain-common)
    - [Onboard Merchant Flow](#onboard-merchant-flow)
    - [Merchant Flow](#merchant-flow)
    - [Merchant Search Flow](#merchant-search-flow)
    - [User Flow](#user-flow)
    - [Order Flow](#order-flow)
    - [Reconciliation Flow](#reconciliation-flow)
    - [Admin Flow](#admin-flow)
- [Infra Explain](#infra-explain)
    - [Load Balance](#load-balance)
    - [Api Gateway](#api-gateway)
    - [Redis cluster](#redis-cluster)
    - [MongoDB](#mongodb)
    - [Cassandra](#cassandra)
    - [Mysql Cluster](#mysql-cluster)
    - [Fire Ware](#file-ware)
    - [Rate Limit](#rate-limit)
    - [Http Server](#http-server)

## Preview <a name="preview"></a>

I will design PayPal eWallet system serving billions of users. This design will go no-function to function, top-down,
common to detail. </br>

## Design <a name="design"></a>

![Paypal-system-design.png](img%2FPaypal-system-design.png)</br>

## Functional Requirements <a name="functional_requirements"></a>

+) Provider on-board new merchant, control merchant.</br>
+) Provide checkout flow smoothly, payment flow smoothly, security.</br>
+) Find order information.</br>
+) Provider Balance Service providers handle race conditions with millions of people checkout. </br>
+) Auto Reconciliation, Manual Reconciliation. </br>
+) User onboard, withdraw, deposit, checkout smoothly, view history order, history balance. </br>
+) Admin Page. </br>

## Non Function <a name="non_function"></a>

+) Low latency. </br>
+) High availability. </br>
+) High consistency. </br>
+) Security. </br>

A payment EWallet system that meets all four factors above with a high traffic, billions of users is a difficult
problem.
To clarify, there are some services that must strictly meet 4 factors: balance, checkout, order ... Search service needs
high availability and does not need absolute consistency. Service order's history requires 4 factors
above, but not absolutely. To thoroughly solve this problem, it is necessary to combine a lot of knowledge and
experience in handling race conditions. Here we go... </br>

## Explain Common <a name="explain-common"></a>

## Onboard Merchant Flow:  <a name="onboard-merchant-flow"></a>

![merchant-flow.png](img%2Fmerchant-flow.png) </br>
A large eWallet like PayPal has billions of users and thousands of merchants around the world. To be a
merchant of PayPal, you will have to register with Merchant Service via Onboard Merchant Flow. The number of
merchants will not be too large, almost never more than 1 million merchants, the data has a clear structure, close
relationships, we only need one mysql for this service. Read information will be cached with Redis Cluster. Technically,
the frequency of reading and writing of this service is not high, the race condition when invalidate cache is low, so it
is only necessary to handle the cache in the most traditional way. When the cache invalidate, a thread will read in
the DB and update the cache. </br>

All events on board will be sent to kafka for other services to search, order... to receive information. </br>

The information to be saved is: { merchant_id, status, created_at, updated_at, active_at, merchant_key,...}. It is the
basic information of the merchant but there are some extremely important information. First, merchant_key. Merchant_key
represents that merchant in terms of security and authentication. There are many ways to secure and authenticate in a
payment gateway, two popular ones are digital signing and JWT. With digital signature, there are two main types:
symmetric key pair signing or single key signing. Here, I assume the basic way is to sign by single key. Merchant_key is
that single key, a merchant who wants to pass through auth must have jwt (in jwt there is a digital signature generated
from merchant_key). On some important payment orders, a digital signature generated by merchant_key is required. </br>

## Merchant Flow:  <a name="merchant-flow"></a>

![merchant-flow.png](img%2Fmerchant-flow.png) </br>
After successfully registering as a merchant of PayPal, the merchant can access information and perform operations
with the PayPal's system.The authentication, author will be done with Auth, Author Service. </br>

Risk Service will collect all risks from Order Service, Merchant Service, Provider Service and assess the risk
information of Partner, of the order. All necessary information will be background calculated by Risk Service, stored in
Redis Cluster to ensure short response times. This information will be saved in MongoDB and read in Redis Cluster.
MongoDB selected criteria for risk assessment are often unstructured, and have low read and write output. </br>

A large project like PayPal will have many providers: banks, payment gateways, e-wallets... All this
information will be taken by the Inbound Service and stored in the Provider Service. It includes onboard new provider,
find, edit, delete,... provider. </br>

## Merchant Search Flow:  <a name="merchant-search-flow"></a>

![merchant-search-flow.png](img%2Fmerchant-search-flow.png)</br>
With eWallet, the search is not as much as ecommerce, it is mainly search operation. However, there are search
needs about advertising campaigns, bonus points, statistics on the results of that campaign. A Search Consumer will
listen to kafka and push important information to the ElasticSearch Cluster. ElasticSearch Cluster is a search
engine that allows full flexible search functionality. Details are available at the
link: https://github.com/Nghiait123456/SystemDesignBigProject/tree/master/BestPracticeChooseDataBase </br>

Search Service will get more at Wear House Service to get more statistical information for merchants. Warehouse Service
will listen in kafka for the events we need to aggregate: there is a new merchant, there is a successful order, a failed
order,... These events are events from event-sourcing in the operating process of the system. . It is possible to get
events from changing data in the DB, such as mysql being written to binlog, a service that pushes changes from binlog to
kafka. </br>

Spack will also listen to kafka, push data to the Hadoop Cluster, the data is processed, format, format, and push the
appropriate events back into kafka. Hadoop is the data source for data engineer and machine learning, AI works. I'm not
an expert on this, I'm not going to talk about it in depth, this is the most general way designed. </br>

## User Flow:  <a name="user-flow"></a>

![user-flow.png](img%2Fuser-flow.png) </br>
User service will manage all user activities: Onboard new user, update, read, delete user... Deposit, WithDraw will be
managed by Balance Service. All user information: { user_id, email, pass_hash, .... } are related information,
structure, Mysql cluster will be selected. The read will be taken in the Redis cluster. Race conditions when cache
invalidate here is not high, because it is a user's personal information, not shared information. When the cache is
invalidate, it can be handled simply that the first thread reads in the DB and updates it back into the cache. </br>

All deposits and withdrawals will be periodically reconciled with Reconciliation Service. The user's authentication and
author entry into Paypal will also be managed by the User Service. </br>

User flow will manage all adding, using, deleting... card of the user. </br>

## Order Flow:  <a name="order-flow"></a>

![order-flow.png](img%2Forder-flow.png)</br>
We have Order Talking Service which serves the entire process of order creation, checkout,... It is the big follow flow
for Order Flow. </br>

The first thing we need to make sure is that only one request can be handled with one order at a time. This is ensured
by the red lock of the redis cluster. </br>

First, the end user will create an order with their partner, and the partner calls the PayPal to create an order at
the PayPal. Order Talking Service will call the Order System to create a new order. Order data that needs absolute
ACID should be saved to Mysql DB Cluster. </br>

There is a point worth noting, Order Talking Service will return the Merchant the order information and a piece of
digital signature. Merchant will pass that information into the browser according to Paypal's form or Paypal's url. The
digital
signature segment serves as the key to security. Users can easily edit information on the front-end, but they cannot
create a suitable digital signature. It destroys any user's attempt to change order information. </br>

When the order is successfully created, the Order Talking Service will create a record on the Redis Cluster: </br>

```
{
order_id
merchant_id
created_at
expiry_time
status: "created"
}
```

Before merchant wants to check out, Order Talking Service will talk to RiskService to check the risk of merchant. If it
fails, it is rejected and returned with the status: "reject_risk_service" and the corresponding error code. The Order
Talking Service
will return a page to the User, which is a callBack Page with the error code and the necessary information being
digitally signed. Risk information will be pre-calculated to be available immediately when information is needed.</br>

Now, the merchant wants to pay for the order, the user will have to click on the Paypal's checkout button. Process will
automatically navigate to Checkout Follow. </br>

The first thing is to check if the digital signature of the order is valid for the merchant. If not, error will be
returned, status is "checkout_error" with error code "error_signature" sent via front end. If valid, a popup pops up,
check user logged in or not, in browser, check cookie ID has passed login, in the app will check the token that has been
logged in. If not logged in, User must login to continue. </br>

The order information will be shown to the user to check. Right now, a check_risk_user event is sent to kafka, the Risk
Service has been run and has results in the background. An event is also sent back to Kafka by Risk Service. When all
checking actions of the user are completed, the user clicks on the checkout button, the request is sent to the Order
Talking Service. In this step, there will be 2 cases where the user chooses to pay with a wallet account and chooses to
pay with External Service Checkout. </br>

If you choose to pay with a wallet account, the Order Talking Service will talk to the Risk Service about the user's
risk. All result of Risk Service was pre-calculated. Any failure, payment will be cancelled. If the user passes the
risk, the Order Talking Service will talk to the
Balance Service requesting a request to change the balance balance. </br>

Here, the user can choose to pay with a third party: visa, bank, ... Order Talking Service will talk to the Risk Service
about the user's
risk. All result of Risk Service was pre-calculated. Any failure, payment will be cancelled. Order Talking Service will
direct the user to the
External Checkout Flow. The result of the payment process will be sent back to the Order Talking Service by External
Checkout Flow via event, callback Url, IPN. </br>

In payment models that require a call to the balance service to check, there will be a difficult problem here.
For orders that must check the amount before payment, Order Talking Service will talk to the Balance Service to request
balance processing. This is a difficult service because of the high number of race conditions and integrity, high real
time. Balance Service needs to ensure fast Merchant withdrawal and 100 percent ACID guarantee. With a large company like
PayPal, there can be tens of thousands of orders to deduct money from a merchant's balance at a time. This number
exceeds the processing capacity of mysql default. Here, there are 2 most popular solutions: sharding mysql or ignoring
the database
in the calculation. The easiest solution to implement and the most likely to increase the load is Sharding Mysql, the
tool chosen here is Mysql Cluster. Mysql Cluster will provide the easiest way to increase mysql performance without much
processing. Another solution is to skip IO, the most famous architecture known is
LMAX(https://martinfowler.com/articles/lmax.html). Digging too deep into LMAX would be within the scope of this
document, I have a project that implements LMAX Service quite similar for
payment-gateway: https://github.com/Nghiait123456/HighPerformancePaymentGateway-BalanceService. </br>
For orders that are payment with a third
party, Checkout Follow will automatically navigate to the 3rd service such as bank, other payment gateway to complete
the transaction. There are 3 possible cases: success, failure, no response. <br>

When all payments are successful, the User will be redirected to the success screen managed by the Order Talking
Service. If the order is successful at 8:05 and the expiry time is 8:10, everything is valid, the Order Talking Service
will update the status: "checkout_success" and send an event to Kafka for the other services to update the DB
accordingly. The expiry time of the order we will place is very large, much larger than my service timeout and related
services, to avoid race conditions over timeout orders with successful orders. However, if the successful order event
comes after the timeout order event, the Order Talking Service will save the status as status: "exception_checkout" with
the corresponding error code. To avoid a race conditions, Order Talking Service will not send success payment event, it
just sends event exception checkout and Service Exception Handle will handle this later. This is necessary and very
rare, so it is allowed to exist in this design. Enabling this will reduce extremely complex race conditions between our
distributed systems. At the beginning of the article, we always only allow 1 event, a request to interact with an order
in Order Talking Service, so there will never be a case, 2 events succeed and expire at the same time.

IPN to Merchant Service will receive successful order information, build IPN and send IPN to merchant. The important
information to verify is the amount, digital signature. </br>
When the order is successful, it will also be redirected
to a notification screen managed by Order Talking Service. In this step, Order Talking Service will build a callback
url, this url points to the url that merchant has registered if the payment is successful. </br>

When the payment fails, the action is the same as the successful payment but with status "error_checkout". The
inventory service will have to listen for this event and rollback inventory. </br>
When the order timeout, the record will be deleted from redis, and the Order Talking Service will also have the same
action procedure as when it fails, only different status : "timeout". The event timeout will be pushed back by the redis
cluster through Kafka and to the OrderTalkingService. Event timeout is valid only and is handled by the order talking
service if the order is in processing status, not the end state. </br>

For internal checkout, the processing steps are similar, except that you don't have to talk to a third party to complete
the checkout. </br>

At this point, the Purchase Follow flow has been completed, I would like to clarify some bottleneck issues. A system
like PayPal can have many millions of orders a day, and an order must be kept for at least several years for audit.
In 10 years, PayPal has 10 * 365 * 5 * 10 ^6 orders, this terrible number is the bottleneck of mysql. DB is too
large will affect mysql's ability to work normally, migration is required. There are many solutions for this, the most
common being cold and hot databases. Orders that are in a final, immutable state can be backed up to warm or cold mysql
clusters. Here, these orders no longer have the ability to change status, it is just a request to read information, and
the reading information will be as simple as querying by OrderId, querying by status, created_at,... me will choose
Cassandra for this service. The Order processing service is an order management service, event notification about any
change of order, order search. The Archiver System will search the row of orders in the last state, send them to the
History Order System. Here, the History Order System will add the order to Cassandra and send the event to Kafka. Order
Processing System when receiving the event, delete the order from mysql. A request to view order information will be
made to the History Order System. </br>

The Error Checking Service will run in the background to check for all irregularities, orders that have not been change
status for too long and notify kafka, process and notify relevant parties. With financial services and complex
process, an Error Checking Service is needed to detect and correct deviations early. </br>

## Reconciliation Flow  <a name="reconciliation-flow"></a>

![reconciliation-flow.png](img%2Freconciliation-flow.png) </br>
Reconciliation is an integral part of any financial product. Simply, we will match the data at the elapsed time.
Reconciliation will take information from the Balance Service, Order History Service and compile it into its own
reconciliation report. Merchant can automatically verify and get this report via Api. There will be a part of the
reports that need to be verified manually. If there is any error, the event will be sent kafka, and notified, the mail
will be sent to the stakeholders and handled manually. Data of Reconciliation Service needs absolute ACID so mysql
cluster will be selected. </br>

In addition to checking with merchants, checking services also conducts checks with Users on deposit and withdraw
issues, any abnormalities will be sent and notified to relevant parties </br>

## Admin Flow <a name="admin-flow"></a>

![admin-folow.png](img%2Fadmin-folow.png) </br>
A payment gateway has a lot of information to set up, manage, and set up. I call it admin service. It will change the
settings for the system, for the merchant, send the kafka change, notify the change to the stakeholders notify the
service. The setup will have structured, relational and non-struct data at the same time. The read and write frequency
is not large for this service, so mysql and mongoDB will be selected. This service will save settings, menus,
maintenance hours, setup time notify, system timeout... Absolute ACID information such as privatel_key, .... will be
saved in mysql, and non-struct information , high changes will be saved in mongoDB. You can absolutely choose only mysql
or mongoDB for this service, because its read and write threshold is not too large. However, choosing 1 of the 2 types,
I will have to have flexible and skillful handling to overcome the disadvantages of the other type. </br>

## Infra Explain  <a name="infra-explain"></a>

## Load Balance  <a name="load-balance"></a>

A large product like PayPal, users are scattered across the globe and at peak times, can have several million rps. (
This
is an assumed number of this design, the actual number may be many times larger). With those peculiarities, I needed a
distributed LB that could intelligently navigate the load and was highly fault tolerant.</br>

I have a more detailed analysis of
this: https://github.com/Nghiait123456/InfraSREDevopsBackendForBigProject/tree/master/InfraSREDevops/1_LoadBalancing#load_balancer_region_base_dns_and_l4lb, https://github.com/Nghiait123456/InfraSREDevopsBackend/InfraSREDevops/
/1_LoadBalancing#load_balancer_with_bgp_software </br>

## Api Gateway  <a name="api-gateway"></a>

I have a more detailed analysis of
this: https://github.com/Nghiait123456/InfraSREDevopsBackendForBigProject/tree/master/InfraSREDevops/26_ApiGateway#type_pai_gateway_in_microservice,
https://github.com/Nghiait123456/InfraSREDevopsBackendForBigProject/tree/master/InfraSREDevops/26_ApiGateway#how_do_choose_api_gateway </br>

## Redis cluster <a name="redis-cluster"></a>

I have a more detailed anlysis of
this : https://github.com/Nghiait123456/InfraSREDevopsBackendForBigProject/blob/master/InfraSREDevops/3_Cache/README.md#cache_cluster_is_require_for_high_load,
https://github.com/Nghiait123456/InfraSREDevopsBackendForBigProject/blob/master/InfraSREDevops/3_Cache/README.md#benchmark_rediss </br>

## MongoDB <a name="mongodb"></a>

When to choose mongoDB and benchmark, I have a detailed description at the
link: https://github.com/Nghiait123456/SystemDesignBigProject/blob/master/BestPracticeChooseDataBase/README.md, https://github.com/Nghiait123456/InfraSREDevopsBackendForBigProject/blob/master/InfraSREDevops/9_NoSql/MongoDb/REAME.md </br>

## Cassandra <a name="cassandra"></a>

When to choose Cassandra and benchmark, I have a detailed description at the
link: https://github.com/Nghiait123456/SystemDesignBigProject/blob/master/BestPracticeChooseDataBase/README.md, https://github.com/Nghiait123456/InfraSREDevopsBackendForBigProject/blob/master/InfraSREDevops/9_NoSql/Cassandra/README.md#benchmark_cassandra </br>

## Mysql Cluster <a name="mysql-cluster"></a>

When to choose Mysql Cluster and benchmark, I have a detailed description at the
link: https://github.com/Nghiait123456/SystemDesignBigProject/blob/master/BestPracticeChooseDataBase/README.md, https://github.com/Nghiait123456/InfraSREDevopsBackendForBigProject/blob/master/InfraSREDevops/8_Sql/Mysql/Sharding/README.md#BenchmarkMysqlCluster </br>

## Fire Ware <a name="file-ware"></a>

Firewall, security and ddos prevention system is an important part. Preventing ddos is a difficult problem, because the
reason the threshold of ddos load is very large, much larger than your infrastructure. Please use third party for this
work. I have a link that describes the problem in
detail: https://github.com/Nghiait123456/DissectLaravel#why_do_not_use_rate_limit_laravel_for_attack_ddos, https://github.com/Nghiait123456/DissectLaravel#best_practice_prevent_attack_ddos</br>

## Rate Limit <a name="rate-limit"></a>

I have detail rate limit in
link: https://github.com/Nghiait123456/InfraSREDevopsBackendForBigProject/tree/master/InfraSREDevops/2_RateLimit </br>

## Http Server <a name="http-server"></a>

I have detail scale out http server in
link: https://github.com/Nghiait123456/InfraSREDevopsBackendForBigProject/tree/master/InfraSREDevops/16_HttpServer </br>



